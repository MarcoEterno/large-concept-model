{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T21:10:20.045527Z",
     "start_time": "2024-08-17T21:10:18.364297Z"
    }
   },
   "source": [
    "# This notebook explores the use of SentenceBERT and spacy to generate concept embeddings from text\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.nn import CosineSimilarity\n",
    "import torch\n",
    "\n",
    "# Load pretrained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Example sentences\n",
    "sentence1 = \"How can I book a flight?\"\n",
    "sentence2 = \"How can I purchase a flight? \"\n",
    "\n",
    "# Tokenize and encode the sentences\n",
    "inputs1 = tokenizer(sentence1, return_tensors='pt')\n",
    "inputs2 = tokenizer(sentence2, return_tensors='pt')\n",
    "\n",
    "# Get the embeddings\n",
    "with torch.no_grad():\n",
    "    embeddings1 = model(**inputs1).last_hidden_state.mean(dim=1)\n",
    "    embeddings2 = model(**inputs2).last_hidden_state.mean(dim=1)\n",
    "\n",
    "# Compute cosine similarity\n",
    "cos = CosineSimilarity(dim=1)\n",
    "similarity = cos(embeddings1, embeddings2)\n",
    "\n",
    "print(f\"Similarity score: {similarity.item()}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcoeterno/mambaforge/envs/large_concept_model/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.9528940320014954\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T17:15:12.707384Z",
     "start_time": "2024-08-17T17:15:06.345161Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "! python -m spacy download en_core_web_sm\n",
    "\n",
    "def extract_concepts(sentence):\n",
    "    # Load spaCy's English language model\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    # Process the sentence\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Extract concepts: noun chunks and optionally named entities\n",
    "    concepts = [chunk.text for chunk in doc.noun_chunks]  # Extract noun chunks\n",
    "\n",
    "    # Optionally, add named entities as concepts\n",
    "    entities = [ent.text for ent in doc.ents]\n",
    "    concepts.extend(entities)\n",
    "    \n",
    "    # Remove duplicates and return\n",
    "    return list(set(concepts))\n",
    "\n",
    "# Example usage\n",
    "sentence = \"Quantum computing and machine learning are transforming the field of artificial intelligence.\"\n",
    "concepts = extract_concepts(sentence)\n",
    "print(concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T17:15:20.966675Z",
     "start_time": "2024-08-17T17:15:20.714749Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load and preprocess data\n",
    "# Assume load_data and preprocess_data are defined to load your dataset\n",
    "data = load_data('dataset.csv')\n",
    "X, y = preprocess_data(data)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=128))  # Adjust input_dim as needed\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T18:14:56.077451Z",
     "start_time": "2024-08-17T18:14:56.028622Z"
    }
   },
   "outputs": [],
   "source": [
    "from textsplit.tools import SimpleSentenceTokenizer\n",
    "from textsplit.algorithm import split_optimal\n",
    "\n",
    "# Load the text\n",
    "text = \"Mars is the fourth planet from the Sun. The surface of Mars is orange-red because it is covered in iron(III) oxide dust, giving it the nickname 'the Red Planet'. Mars is among the brightest objects in Earth's sky, and its high-contrast albedo features have made it a common subject for telescope viewing. It is classified as a terrestrial planet and is the second smallest of the Solar System's planets with a diameter of 6,779 km (4,212 mi). In terms of orbital motion, a Martian solar day (sol) is equal to 24.5 hours, and a Martian solar year is equal to 1.88 Earth years (687 Earth days). Mars has two natural satellites that are small and irregular in shape: Phobos and Deimos.\"\n",
    "\n",
    "# Tokenize the text into sentences\n",
    "sentence_tokenizer = SimpleSentenceTokenizer()\n",
    "sentences = sentence_tokenizer(text)\n",
    "\n",
    "# Split the text into segments\n",
    "splits = split_optimal(sentences, penalty=0.1)\n",
    "\n",
    "# Print the segments\n",
    "for segment in splits:\n",
    "        print(\" \".join(sentences[segment[0]:segment[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T21:08:20.407774Z",
     "start_time": "2024-08-17T21:08:18.395592Z"
    }
   },
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TankuVie/bert-finetuned-unpunctual-text-segmentation\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"TankuVie/bert-finetuned-unpunctual-text-segmentation\")"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T21:18:58.126545Z",
     "start_time": "2024-08-17T21:18:58.112291Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "# Load the text\n",
    "text = \"Mars is the fourth planet from the Sun. The surface of Mars is orange-red because it is covered in iron(III) oxide dust, giving it the nickname 'the Red Planet'. Mars is among the brightest objects in Earth's sky, and its high-contrast albedo features have made it a common subject for telescope viewing. It is classified as a terrestrial planet and is the second smallest of the Solar System's planets with a diameter of 6,779 km (4,212 mi). In terms of orbital motion, a Martian solar day (sol) is equal to 24.5 hours, and a Martian solar year is equal to 1.88 Earth years (687 Earth days). Mars has two natural satellites that are small and irregular in shape: Phobos and Deimos.\"\n",
    "\n",
    "# Tokenize the text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "inputs\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7733,  2003,  1996,  2959,  4774,  2013,  1996,  3103,  1012,\n",
       "          1996,  3302,  1997,  7733,  2003,  4589,  1011,  2417,  2138,  2009,\n",
       "          2003,  3139,  1999,  3707,  1006,  3523,  1007, 15772,  6497,  1010,\n",
       "          3228,  2009,  1996,  8367,  1005,  1996,  2417,  4774,  1005,  1012,\n",
       "          7733,  2003,  2426,  1996, 26849,  5200,  1999,  3011,  1005,  1055,\n",
       "          3712,  1010,  1998,  2049,  2152,  1011,  5688,  2632, 28759,  2838,\n",
       "          2031,  2081,  2009,  1037,  2691,  3395,  2005, 12772, 10523,  1012,\n",
       "          2009,  2003,  6219,  2004,  1037, 12350,  4774,  1998,  2003,  1996,\n",
       "          2117, 10479,  1997,  1996,  5943,  2291,  1005,  1055, 11358,  2007,\n",
       "          1037,  6705,  1997,  1020,  1010,  6255,  2683,  2463,  1006,  1018,\n",
       "          1010, 18164,  2771,  1007,  1012,  1999,  3408,  1997, 13943,  4367,\n",
       "          1010,  1037, 20795,  5943,  2154,  1006, 14017,  1007,  2003,  5020,\n",
       "          2000,  2484,  1012,  1019,  2847,  1010,  1998,  1037, 20795,  5943,\n",
       "          2095,  2003,  5020,  2000,  1015,  1012,  6070,  3011,  2086,  1006,\n",
       "          6273,  2581,  3011,  2420,  1007,  1012,  7733,  2038,  2048,  3019,\n",
       "         14549,  2008,  2024,  2235,  1998, 12052,  1999,  4338,  1024,  6887,\n",
       "         16429,  2891,  1998, 14866, 15530,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T06:43:29.738750Z",
     "start_time": "2024-08-18T06:43:29.660965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the predicted segment labels\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    print(outputs)\n",
    "    predicted_labels = outputs.last_hidden_state.argmax(dim=2)\n",
    "    print(predicted_labels)\n",
    "\n",
    "tokenizer.decode(predicted_labels[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-1.0204, -0.1012,  0.2194,  ...,  0.2456,  0.6954,  1.1194],\n",
      "         [ 0.3022,  1.0192,  0.4375,  ..., -0.0246,  0.9316,  0.6587],\n",
      "         [-1.4419, -0.0301,  0.3008,  ...,  0.1404,  0.4928,  0.7091],\n",
      "         ...,\n",
      "         [-0.8128, -0.0673, -0.9113,  ..., -1.0055,  1.0571, -0.5666],\n",
      "         [-0.8968, -0.8013, -0.2706,  ...,  0.6588,  0.9557, -0.3104],\n",
      "         [-0.9273, -0.0457,  0.2136,  ...,  0.6011,  0.2943, -0.0431]]]), pooler_output=tensor([[-0.8164, -0.5264, -0.9291,  0.6446,  0.8406, -0.3913, -0.1817,  0.5292,\n",
      "         -0.8709, -1.0000, -0.7165,  0.9693,  0.9673,  0.2042,  0.3778, -0.5459,\n",
      "         -0.3514, -0.5353,  0.4212,  0.9009,  0.3931,  1.0000, -0.4791,  0.5602,\n",
      "          0.4955,  0.9852, -0.7595,  0.8237,  0.9070,  0.7706, -0.1224,  0.4476,\n",
      "         -0.9929, -0.1334, -0.9056, -0.9813,  0.5890, -0.4938,  0.1892, -0.2136,\n",
      "         -0.7540,  0.5457,  1.0000, -0.2556,  0.6084, -0.2269, -1.0000,  0.4020,\n",
      "         -0.6858,  0.9676,  0.7992,  0.9716,  0.2154,  0.4242,  0.6266, -0.6711,\n",
      "         -0.1947,  0.1431, -0.4735, -0.6609, -0.5841,  0.2100, -0.8784, -0.5888,\n",
      "          0.9713,  0.8360, -0.0982, -0.2178,  0.1134,  0.0135,  0.4359,  0.0408,\n",
      "         -0.4443, -0.5807,  0.7075,  0.3518, -0.7949,  1.0000, -0.3520, -0.9851,\n",
      "          0.8769,  0.8051,  0.8114, -0.5988,  0.5157, -1.0000,  0.6801, -0.0980,\n",
      "         -0.9803,  0.4642,  0.6687, -0.2807,  0.4921,  0.7860,  0.0940, -0.6184,\n",
      "         -0.4398, -0.9772, -0.3745, -0.4218,  0.2067, -0.2979, -0.5006, -0.2471,\n",
      "          0.4836, -0.6905,  0.1923,  0.2743, -0.3257,  0.4108,  0.7433, -0.4736,\n",
      "          0.5413, -0.8319,  0.5377, -0.4724, -0.9911, -0.8133, -0.9854,  0.4666,\n",
      "         -0.2365, -0.2867,  0.6542, -0.5627,  0.6631, -0.2708, -0.9670, -1.0000,\n",
      "         -0.5463, -0.4933, -0.2356, -0.2699, -0.9807, -0.9658,  0.6614,  0.8928,\n",
      "          0.2959,  1.0000, -0.3894,  0.8793, -0.0546, -0.8092,  0.8765, -0.4455,\n",
      "          0.6082, -0.5695, -0.0268,  0.3956, -0.6986,  0.3338, -0.8219, -0.4924,\n",
      "         -0.8155, -0.6870, -0.4738,  0.7415, -0.5672, -0.9507, -0.0785, -0.2398,\n",
      "         -0.2787,  0.7120,  0.6742,  0.4067, -0.3341,  0.5997, -0.7189,  0.5790,\n",
      "         -0.6188, -0.3090,  0.3472, -0.5859, -0.8725, -0.9779, -0.4969,  0.3111,\n",
      "          0.9823,  0.6975,  0.4909,  0.7519, -0.4319,  0.7086, -0.9611,  0.9839,\n",
      "         -0.1587,  0.3559, -0.8013,  0.4873, -0.6356, -0.2848,  0.2644, -0.6897,\n",
      "         -0.8238, -0.1698, -0.5967, -0.4992, -0.8708,  0.4295, -0.1611, -0.4294,\n",
      "         -0.2788,  0.8092,  0.7135,  0.2824,  0.6012,  0.7152, -0.7897, -0.0614,\n",
      "          0.1416,  0.2616,  0.1608,  0.9859, -0.6917, -0.2826, -0.6735, -0.9655,\n",
      "          0.1778, -0.7223, -0.2932, -0.6867,  0.7366, -0.8155, -0.0796,  0.3042,\n",
      "          0.5078, -0.1466,  0.3622, -0.8067,  0.4379, -0.3854,  0.9767,  0.9484,\n",
      "         -0.5945, -0.7335,  0.9639, -0.9687, -0.7304, -0.4966, -0.5174,  0.4876,\n",
      "         -0.6004,  0.9916,  0.9227,  0.7261, -0.8389, -0.8086, -0.4937, -0.3439,\n",
      "         -0.2074, -0.3502,  0.9440,  0.8372,  0.6315,  0.5508, -0.6080,  0.3794,\n",
      "         -0.9807, -0.9608, -0.9737, -0.0921, -0.9901,  0.9275,  0.3399,  0.8957,\n",
      "         -0.5927, -0.6108, -0.9331,  0.0854,  0.1663,  0.6361, -0.5366, -0.6425,\n",
      "         -0.6647, -0.9480,  0.1576,  0.0659, -0.6580,  0.2183, -0.8130,  0.5312,\n",
      "          0.5562,  0.5989, -0.9123,  0.9089,  1.0000,  0.9662,  0.6881, -0.1473,\n",
      "         -1.0000, -0.9801,  1.0000, -0.9979, -1.0000, -0.7737, -0.4514,  0.0138,\n",
      "         -1.0000, -0.4820, -0.0417, -0.7918,  0.7538,  0.9592,  0.0497, -1.0000,\n",
      "          0.8801,  0.8507, -0.8662,  0.9689, -0.4875,  0.9618,  0.3073,  0.6382,\n",
      "         -0.3289,  0.4862, -0.8805, -0.5235, -0.6706, -0.9275,  0.9999,  0.3204,\n",
      "         -0.4754, -0.6520,  0.7535, -0.2516, -0.1598, -0.9240, -0.2868,  0.7056,\n",
      "          0.7039,  0.3627,  0.4404, -0.0271,  0.4467,  0.2434, -0.6266,  0.8398,\n",
      "         -0.8449, -0.0494,  0.3333,  0.4720, -0.4520, -0.9649,  0.8750, -0.5145,\n",
      "          0.8702,  1.0000,  0.9038, -0.4373,  0.4849,  0.3883, -0.3578,  1.0000,\n",
      "          0.7543, -0.9802, -0.8683,  0.7665, -0.7227, -0.7336,  0.9995, -0.3332,\n",
      "         -0.8634, -0.7991,  0.9935, -0.9893,  0.9993, -0.5344, -0.9460,  0.9223,\n",
      "          0.8487, -0.7356, -0.8049, -0.0317, -0.0152,  0.1212, -0.2505,  0.7054,\n",
      "          0.2700, -0.1418,  0.5537,  0.3706, -0.8233,  0.4039, -0.8940, -0.0022,\n",
      "          0.9648,  0.4740, -0.2940, -0.0348, -0.2663, -0.8912, -0.9233,  0.7108,\n",
      "          1.0000, -0.2380,  0.9435,  0.1388, -0.1993,  0.1097,  0.6852,  0.7057,\n",
      "         -0.3190, -0.6564,  0.8699, -0.0290, -0.9927, -0.0299,  0.1973, -0.2134,\n",
      "          0.9999,  0.0997,  0.4978,  0.4715,  0.9970, -0.1006, -0.1511,  0.9240,\n",
      "          0.9904, -0.4580,  0.8495,  0.0379, -0.9467, -0.4556, -0.5228, -0.0401,\n",
      "         -0.9337, -0.0545, -0.9389,  0.9411,  0.9845,  0.4717,  0.4027,  0.8776,\n",
      "          1.0000, -0.9940,  0.1992,  0.8953, -0.6695, -1.0000,  0.2861, -0.4366,\n",
      "         -0.1520, -0.9422, -0.3317,  0.3116, -0.9704,  0.8168,  0.8323, -0.1639,\n",
      "         -0.9636, -0.7204,  0.3291,  0.3378, -0.9971, -0.1836, -0.5029,  0.5405,\n",
      "         -0.3003, -0.8070, -0.3775, -0.4915,  0.5179, -0.4999,  0.7842,  0.8972,\n",
      "          0.9434, -0.9531, -0.4430, -0.0969, -0.5025,  0.6097, -0.5333, -0.9657,\n",
      "         -0.4037,  1.0000, -0.6491,  0.8521,  0.2579,  0.3733, -0.1909,  0.3295,\n",
      "          0.9835,  0.5171, -0.5286, -0.9365,  0.9129, -0.5692,  0.5544,  0.8548,\n",
      "          0.4179,  0.7645,  0.9299,  0.5055, -0.0823,  0.2103,  0.7992, -0.1872,\n",
      "         -0.3588, -0.1853, -0.0118, -0.4730,  0.7849,  1.0000,  0.3374,  0.5942,\n",
      "         -0.9844, -0.8648, -0.6691,  1.0000,  0.8967, -0.6847,  0.6802,  0.6272,\n",
      "         -0.5114,  0.0034, -0.2271, -0.2945,  0.3328, -0.0251,  0.9632, -0.4484,\n",
      "         -0.9862, -0.5977,  0.4456, -0.9307,  1.0000, -0.6325, -0.3043, -0.3617,\n",
      "         -0.7613, -0.9895,  0.0965, -0.9583, -0.4098,  0.4471,  0.9460,  0.5655,\n",
      "         -0.8680, -0.7518,  0.9483,  0.8885, -0.9455, -0.8874,  0.9299, -0.8051,\n",
      "          0.7466,  1.0000,  0.5924,  0.7036,  0.2425, -0.2233,  0.4491, -0.7537,\n",
      "          0.3555, -0.7892, -0.3965, -0.2770,  0.5458, -0.5587, -0.9538,  0.4302,\n",
      "          0.3119, -0.8192, -0.6202, -0.2310,  0.4777,  0.7349, -0.3563, -0.1815,\n",
      "          0.3735, -0.1203, -0.5299, -0.5032, -0.5752, -1.0000,  0.5376, -1.0000,\n",
      "          0.8937, -0.2315, -0.2995,  0.8087,  0.8884,  0.6782, -0.5405, -0.9650,\n",
      "          0.2753,  0.5089, -0.4163, -0.4767, -0.3512,  0.4836, -0.0868,  0.3029,\n",
      "         -0.8251,  0.5238, -0.5730,  1.0000,  0.2056, -0.6798, -0.1503,  0.2122,\n",
      "         -0.5245,  1.0000, -0.0834, -0.9623,  0.2748, -0.8129, -0.5004,  0.5561,\n",
      "          0.2524, -0.7021, -0.9744,  0.2566, -0.3066, -0.8268,  0.5130, -0.4873,\n",
      "         -0.4002,  0.1386,  0.9693,  0.9796,  0.4406,  0.5826, -0.9335, -0.4373,\n",
      "          0.9371,  0.5018, -0.4255,  0.2863,  1.0000,  0.4421, -0.7895, -0.0441,\n",
      "         -0.7977, -0.1880, -0.6692,  0.4863,  0.3800,  0.9004, -0.2786,  0.8764,\n",
      "         -0.8887,  0.0054, -0.7604, -0.6367,  0.3777, -0.8014, -0.9795, -0.9792,\n",
      "          0.7957, -0.3635, -0.1513,  0.4773,  0.3477,  0.5287,  0.5307, -1.0000,\n",
      "          0.9406,  0.4089,  0.9044,  0.9452,  0.8014,  0.7853,  0.4991, -0.9794,\n",
      "          0.1255, -0.3888, -0.2735,  0.3756,  0.7749,  0.7059,  0.3818, -0.3503,\n",
      "         -0.6661, -0.5594, -0.9881, -0.9899,  0.5388, -0.7812,  0.3205,  0.9340,\n",
      "         -0.6386, -0.2224, -0.2502, -0.9395, -0.2389,  0.5696, -0.2131,  0.0493,\n",
      "          0.2989,  0.7226,  0.4040,  0.9787, -0.8784,  0.3271, -0.9497,  0.4068,\n",
      "          0.9862, -0.9540,  0.2218,  0.6769, -0.1862,  0.5249, -0.5214,  0.1375,\n",
      "          0.9475, -0.4218,  0.3901, -0.4632, -0.0311, -0.5380, -0.3597, -0.6255,\n",
      "         -0.7988,  0.7503,  0.1199,  0.8392,  0.8853, -0.2607, -0.5747, -0.1456,\n",
      "         -0.6688, -0.8863,  0.0370, -0.1141,  0.1923,  0.7968, -0.0732,  0.9934,\n",
      "         -0.0542, -0.3730, -0.3088, -0.6806,  0.4145, -0.8888, -0.6757, -0.6427,\n",
      "          0.6144,  0.3632,  1.0000, -0.6947, -0.9205, -0.7878, -0.4695,  0.4441,\n",
      "         -0.5715, -1.0000,  0.4243, -0.7555,  0.7504, -0.7817,  0.9300, -0.8438,\n",
      "         -0.5665, -0.4882,  0.7701,  0.9468, -0.4765, -0.6289,  0.7957, -0.8437,\n",
      "          0.9914,  0.5552, -0.8392,  0.2724,  0.8399, -0.8996, -0.6111,  0.3545]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n",
      "tensor([[205, 589, 352, 352, 211, 506, 286, 352, 604, 150, 352,  48, 352, 281,\n",
      "         352, 700, 229, 352,  81, 352, 352, 352,   7, 352, 149,  81, 172,  65,\n",
      "         352, 756, 352, 352, 352, 578, 229, 352, 352, 639, 172, 555, 281, 352,\n",
      "         266, 352, 352,  47,  48, 338, 670, 352,   7, 756, 633, 352,  55, 229,\n",
      "         352, 410, 281, 410, 229, 352, 352, 659, 352, 752, 739, 167, 365, 555,\n",
      "         352, 352, 102, 379, 281,   2,   7, 633, 352, 352, 120, 505, 286, 229,\n",
      "         604,  19, 193, 352, 281, 352, 352, 352, 441, 606, 225, 604, 225, 225,\n",
      "         352,  80, 604, 660, 184, 150, 150, 410,  89, 229, 604, 410, 756, 410,\n",
      "         752, 410, 598, 352, 425, 150, 172, 470, 172, 316, 172, 601,  99,  92,\n",
      "         470, 767,   1, 454, 262, 670, 483,  99, 463, 172,  20,  13, 454, 352,\n",
      "         505, 463,  13, 410, 150, 555, 281, 429, 333,  48, 352,  55, 352, 606,\n",
      "         229, 454,  23, 352, 225, 352, 365, 165, 229, 225,  73, 172, 308]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[unused200] [unused584] [unused347] [unused347] [unused206] [unused501] [unused281] [unused347] [unused599] [unused145] [unused347] [unused47] [unused347] [unused276] [unused347] [unused695] [unused224] [unused347] [unused80] [unused347] [unused347] [unused347] [unused6] [unused347] [unused144] [unused80] [unused167] [unused64] [unused347] [unused751] [unused347] [unused347] [unused347] [unused573] [unused224] [unused347] [unused347] [unused634] [unused167] [unused550] [unused276] [unused347] [unused261] [unused347] [unused347] [unused46] [unused47] [unused333] [unused665] [unused347] [unused6] [unused751] [unused628] [unused347] [unused54] [unused224] [unused347] [unused405] [unused276] [unused405] [unused224] [unused347] [unused347] [unused654] [unused347] [unused747] [unused734] [unused162] [unused360] [unused550] [unused347] [unused347] [SEP] [unused374] [unused276] [unused1] [unused6] [unused628] [unused347] [unused347] [unused115] [unused500] [unused281] [unused224] [unused599] [unused18] [unused188] [unused347] [unused276] [unused347] [unused347] [unused347] [unused436] [unused601] [unused220] [unused599] [unused220] [unused220] [unused347] [unused79] [unused599] [unused655] [unused179] [unused145] [unused145] [unused405] [unused88] [unused224] [unused599] [unused405] [unused751] [unused405] [unused747] [unused405] [unused593] [unused347] [unused420] [unused145] [unused167] [unused465] [unused167] [unused311] [unused167] [unused596] [unused98] [unused91] [unused465] [unused762] [unused0] [unused449] [unused257] [unused665] [unused478] [unused98] [unused458] [unused167] [unused19] [unused12] [unused449] [unused347] [unused500] [unused458] [unused12] [unused405] [unused145] [unused550] [unused276] [unused424] [unused328] [unused47] [unused347] [unused54] [unused347] [unused601] [unused224] [unused449] [unused22] [unused347] [unused220] [unused347] [unused360] [unused160] [unused224] [unused220] [unused72] [unused167] [unused303]'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Extract segments based on predicted labels\n",
    "segments = []\n",
    "segment = []\n",
    "for i, label in enumerate(predicted_labels[0]):\n",
    "    if label == 1:\n",
    "        segments.append(segment)\n",
    "        segment = []\n",
    "    segment.append(tokenizer.convert_ids_to_tokens(inputs.input_ids[0][i].item()))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T21:08:53.620536Z",
     "start_time": "2024-08-17T21:08:53.615404Z"
    }
   },
   "source": [
    "segments = [\" \".join(segment) for segment in segments if segment]\n",
    "print(segments)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', \"Mars is the fourth planet from the Sun . The surface of Mars is orange - red because it is covered in iron ( III ) o ##xide dust , giving it the nickname ' the Red Planet ' . Mars is among the bright ##est objects in Earth ' s sky , and its high - contrast albedo features have made it a common subject for tele ##scope view ##ing . It is classified as a terrestrial planet and is the second smallest of the Solar System ' s planets with a diameter of 6 , 779 km ( 4 , 212 mi ) .\", 'In terms of orbital motion , a Mart ##ian solar day ( sol ) is equal to 24 . 5 hours , and a Mart ##ian solar year is equal to 1 . 88 Earth years ( 687 Earth days ) .']\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['[CLS]', \"Mars is the fourth planet from the Sun . The surface of Mars is orange - red because it is covered in iron ( III ) o ##xide dust , giving it the nickname ' the Red Planet ' . Mars is among the bright ##est objects in Earth ' s sky , and its high - contrast albedo features have made it a common subject for tele ##scope view ##ing . It is classified as a terrestrial planet and is the second smallest of the Solar System ' s planets with a diameter of 6 , 779 km ( 4 , 212 mi ) .\", 'In terms of orbital motion , a Mart ##ian solar day ( sol ) is equal to 24 . 5 hours , and a Mart ##ian solar year is equal to 1 . 88 Earth years ( 687 Earth days ) .']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
